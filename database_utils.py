# database_utils.py

import pandas as pd
import csv
from db_connector import execute_query


def get_db_schema_for_llm(generated_tables):
    """
    Generates a simplified DDL string (CREATE TABLE) from the DataFrames.
    This is the input for the LLM in the NL -> SQL phase.
    """
    ddl_schema = ""
    for table_name, df in generated_tables.items():
        if 'Error' in df.columns:
            continue
            
        columns_ddl = []
        for col_name, dtype in df.dtypes.items():
            sql_type = "VARCHAR"
            if "int" in str(dtype):
                sql_type = "INTEGER"
            elif "float" in str(dtype):
                sql_type = "NUMERIC"
            elif "datetime" in str(dtype):
                sql_type = "TIMESTAMP"
            
            pk_constraint = " PRIMARY KEY" if col_name.lower() == 'id' and not columns_ddl else ""
            
            columns_ddl.append(f"  {col_name} {sql_type}{pk_constraint}")
        
        ddl_schema += f"CREATE TABLE {table_name} (\n"
        ddl_schema += ",\n".join(columns_ddl)
        ddl_schema += "\n);\n\n"
        
    return ddl_schema

def run_sql_query(sql_query):
    """
    Executes the SQL query translated by the LLM in the actual PostgreSQL database.
    
    Args:
        sql_query (str): The SQL query generated by Gemini.
        
    Returns:
        pd.DataFrame: DataFrame with the results from the DB or an error message.
    """

    return execute_query(sql_query, fetch_results=True)


from db_connector import execute_query


def setup_db_with_data(generated_tables):
    """
    Creates the tables and populates them with the generated data in PostgreSQL.
    Returns a success message or the first error.
    """
    for table_name, df in generated_tables.items():
        if 'Error' in df.columns:
            continue
            
        drop_query = f"DROP TABLE IF EXISTS {table_name} CASCADE;"
        execute_query(drop_query, fetch_results=False)
        
        ddl_schema = get_db_schema_for_llm({table_name: df})
        if ddl_schema:
            result_df = execute_query(ddl_schema, fetch_results=False)
            if 'Error' in result_df.columns:
                return result_df['Error'].iloc[0]
                
        from io import StringIO
        buffer = StringIO()

        df.to_csv(buffer, index=False, header=False, quoting=csv.QUOTE_NONNUMERIC)
        buffer.seek(0)
        
        conn = None
        try:
            from db_connector import get_db_connection
            conn = get_db_connection()
            cur = conn.cursor()
            cur.copy_from(
                buffer,
                table_name,
                sep=",",
                columns=df.columns
            )
            conn.commit()
        except Exception as e:
            if conn: conn.rollback()
            return f"Error inserting into {table_name}: {e}"
        finally:
            if conn: cur.close(); conn.close()

    return "Tables and data inserted successfully into PostgreSQL."